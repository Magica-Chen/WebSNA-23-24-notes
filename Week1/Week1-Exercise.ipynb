{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE**: Exercie 2 and 3 will only work on your own machine (not via noteable, I think). Also: You'll need to unzip the chrome driver in the folder where your notebook is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just using beautiful soup go to the description of this course and extract the number of SCQF level for it. http://www.drps.ed.ac.uk/22-23/dpt/cxcmse11427.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spoiler alert: the content should be 'SCQF Level ...'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*hint*: you can use in to check for occurance of a word in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:22:41.768973Z",
     "start_time": "2023-01-15T22:22:41.754967Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'banana' in 'a sentence with bananas':\n",
    "    print('this sentence has a word banana in it')\n",
    "\n",
    "# if word in sentence:\n",
    "#     print('this sentence has a word in it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:22:43.374468Z",
     "start_time": "2023-01-15T22:22:43.096736Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install bs4\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:22:44.649613Z",
     "start_time": "2023-01-15T22:22:44.493831Z"
    }
   },
   "outputs": [],
   "source": [
    "# website address\n",
    "page = 'http://www.drps.ed.ac.uk/22-23/dpt/cxcmse11427.htm'\n",
    "\n",
    "# open the url and store the website\n",
    "website = urlopen(page)\n",
    "\n",
    "# convert the website's content, for this a parser is needed. In this case a html parser\n",
    "soup = BeautifulSoup(website, 'html.parser')\n",
    "\n",
    "# Retrieve the cell that contains 'SCQF Level'\n",
    "# ....\n",
    "\n",
    "# hints:\n",
    "#     what type of a tag is it in? how can you get all items of that type? \n",
    "#     how will you check if they incude these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:20:09.653625Z",
     "start_time": "2023-01-15T22:20:09.644635Z"
    }
   },
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the Google map, Edinburgh castle: https://www.google.com/maps/place/Edinburgh+Castle/@55.9485977,-3.2021022,17z/data=!4m5!3m4!1s0x4887c79a2099c0f7:0x469a1eebe54c0a58!8m2!3d55.9485947!4d-3.1999135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we try to find all reviews of Edinburgh castle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:23:09.035397Z",
     "start_time": "2023-01-15T22:23:09.030400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install selenium \n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:23:11.670964Z",
     "start_time": "2023-01-15T22:23:11.657972Z"
    }
   },
   "outputs": [],
   "source": [
    "# define method that will create a browser, suitable to your operating system\n",
    "import sys\n",
    "def get_a_browser():\n",
    "    if sys.platform.startswith('win32') or sys.platform.startswith('cygwin'):\n",
    "        return webdriver.Chrome() # windows\n",
    "    else:\n",
    "        return webdriver.Chrome('./chromedriver') # mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:31:23.918586Z",
     "start_time": "2023-01-15T22:31:08.183430Z"
    }
   },
   "outputs": [],
   "source": [
    "browser = get_a_browser()\n",
    "\n",
    "# the url we want to open\n",
    "# fill in the correct url for google map, Edinburgh castle!\n",
    "# You can also try other places\n",
    "# Open Google Maps, and search, \"Edinburgh Castle\", Copy the url and paste it here\n",
    "\n",
    "url = '.....'\n",
    "# the browser will start and load the webpage\n",
    "browser.get(url)\n",
    "\n",
    "# we wait 1 second to let the page load everything\n",
    "time.sleep(1)\n",
    "\n",
    "# Google map has cookies warning, just accept the cookies\n",
    "\n",
    "# Find XPATH of cookies button, \n",
    "accept_cookies = browser.find_element(By.XPATH, '...')\n",
    "print(accept_cookies)\n",
    "accept_cookies.click();\n",
    "time.sleep(3)\n",
    "\n",
    "# Get total number of reviews\n",
    "# Find Xpath of total number of reviews\n",
    "total_number_of_reviews = browser.find_element(By.XPATH,\n",
    "                                               '...').text.split(\" \")[0]\n",
    "total_number_of_reviews = int(total_number_of_reviews[1:-1].replace(',','')) if ',' in total_number_of_reviews else int(total_number_of_reviews)#Find scroll layout\n",
    "\n",
    "# go to all reviews page\n",
    "# Find XPATH of all review link\n",
    "all_reviews_page = browser.find_element(By.XPATH,\n",
    "                                        '...').click()\n",
    "# some other xpath may work, you can have a try!\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:31:49.715169Z",
     "start_time": "2023-01-15T22:31:38.445986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scroll down to access all reviews, first of all, let's find the element!\n",
    "# Find XPATH of Scroll button!\n",
    "scrollable_div = browser.find_element(By.XPATH,\n",
    "                                      '...')#Scroll as many times as necessary to load all reviews\n",
    "\"\"\"\n",
    "Google map reviews display 10 per scoll down, so in total, we need to run round(total_number_of_reviews/10 - 1) times\n",
    "\"\"\"\n",
    "# for i in range(0,(round(total_number_of_reviews/10 - 1))):\n",
    "# # However, in order to run fast, we can just load part of all\n",
    "for i in range(0,10):\n",
    "    browser.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', \n",
    "            scrollable_div)\n",
    "    time.sleep(1)\n",
    "\n",
    "#extract the info\n",
    "response = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "#Find the relevant class names!\n",
    "reviews = response.find_all('span', class_='...', text=True)\n",
    "dates = response.find_all('span', class_='...', text=True)\n",
    "rates = response.find_all('span', class_=\"...\")\n",
    "users = response.find_all('div', class_='...')\n",
    "\n",
    "reviews_text=[]\n",
    "dates_text = []\n",
    "users_text = []\n",
    "rates_int = []\n",
    "\n",
    "for i in range(len(reviews)):\n",
    "    reviews_text.append(reviews[i].text)\n",
    "    dates_text.append(dates[i].text)\n",
    "    rates_int.append(int(rates[i]['aria-label'][1]))\n",
    "    users_text.append(users[i]['aria-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:31:55.421919Z",
     "start_time": "2023-01-15T22:31:55.403930Z"
    }
   },
   "outputs": [],
   "source": [
    "#Build up a pandas dataframe to store the dataset\n",
    "df = pd.DataFrame({\"users\":users_text, \n",
    "                   \"rates\":rates_int, \n",
    "                   \"review\":reviews_text, \n",
    "                   \"dates\":dates_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T22:31:59.315324Z",
     "start_time": "2023-01-15T22:31:59.283347Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the same code you used before to retrieve all Tweets of President Biden, or any Tweeter you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the number of retweets\n",
    "* Write the scores to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method that will create a browser, suitable to your operating system\n",
    "import sys\n",
    "def get_a_browser():\n",
    "    if sys.platform.startswith('win32') or sys.platform.startswith('cygwin'):\n",
    "        return webdriver.Chrome() # windows\n",
    "    else:\n",
    "        return webdriver.Chrome('./chromedriver') # mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch the browser\n",
    "browser = get_a_browser()\n",
    "\n",
    "# launch the page you want to look at\n",
    "twitter_url = u'......'\n",
    "\n",
    "# Add the search term\n",
    "query = ''\n",
    "\n",
    "# Create the url\n",
    "url = twitter_url+query\n",
    "\n",
    "# Get the page\n",
    "browser.get(url)\n",
    "\n",
    "# Let the Tweets load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find the body of the page\n",
    "body = browser.find_element(By.TAG_NAME,'body')\n",
    "\n",
    "# Keep scrolling down using a simulation of the PAGE_DOWN button\n",
    "for _ in range(20):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "# Get the scores from the tweets and store them\n",
    "# ...\n",
    "    \n",
    "# Write them to csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
