{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6281a2",
   "metadata": {},
   "source": [
    "**Disclaimer**: This educational content, including any code examples, is provided for instructional purposes only. The author does not endorse or encourage the unauthorised or illegal scraping of websites.\n",
    "\n",
    "While Python with releveant libraries can be used for web scraping, it's crucial to conduct scraping activities in compliance with applicable laws, the website's terms of service, and ethical considerations. Always review and respect the rules set by the website you are scraping to ensure legal and responsible data collection practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3cc272",
   "metadata": {},
   "source": [
    "#  Week 1: Web and Web Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba88fbf",
   "metadata": {},
   "source": [
    "## Scraping an html page (loading and searching it's contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6461cbd",
   "metadata": {},
   "source": [
    "* Local: saved in a file on your computer\n",
    "* Remote: somewhere on the web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac056db",
   "metadata": {},
   "source": [
    "To fully understand this notebook, please open `example_html.html` file in another tab, and open it's `example_html.html`'s source code in a third tab (or even better: in browser's view > developer tools). You will see in a minute what is the exact address in that file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84395eee",
   "metadata": {},
   "source": [
    "For scraping, we need a few of different libraries, most notably Beautifulsoup. Let's first import these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4567524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404781d",
   "metadata": {},
   "source": [
    "We can simply enter a web page as a string and open it. Afterwards, BeautifulSoup converts it into a BeautifulSoup object which has many interesting functions and attributes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9539563",
   "metadata": {},
   "source": [
    "### Local Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd481e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now we use a local file (os.getcwd() gets the Current Working Directory, aka. the folder you're in)\n",
    "file_url = \"file:///\"+os.getcwd()+\"/example_html.html\"\n",
    "website_source_code = urlopen(file_url)\n",
    "\n",
    "# convert the website's content, for this a parser is needed. In this case a html parser\n",
    "soup = BeautifulSoup(website_source_code, 'html.parser')\n",
    "\n",
    "# # Convert the website's content using a parser, we can also use \"lxml\"\n",
    "# soup = BeautifulSoup(website, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a6457",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# here's a complete html of the page, but it's easier to read if you open it's source using the url above\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .find_all retrieves all tags containing 'h1':\n",
    "h1Tags = soup.find_all('h1')\n",
    "for h1 in h1Tags:\n",
    "    print('Complete tag code: ', h1)\n",
    "    print(\"Just the text in the tag: \", h1.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43217984",
   "metadata": {},
   "source": [
    "However, it does not work with attributes of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ee730",
   "metadata": {},
   "outputs": [],
   "source": [
    "titleTags = soup.find_all('title')\n",
    "for title in titleTags:\n",
    "    print('Complete tag code: ', title)\n",
    "    print(\"Just the text in the tag: \", title.text)\n",
    "    \n",
    "# nothing will be printed. there are no tags <title> </title> there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50043f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4148c8c0",
   "metadata": {},
   "source": [
    "## Understanding the html is all about finding components you need:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce23f0",
   "metadata": {},
   "source": [
    "* .find_all( ) will find all things that match criteria, in a **list**\n",
    "* .find( ) will find just the **first** item that mathes the criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d52022",
   "metadata": {},
   "source": [
    "You can use it on the whole website, like `a_table = soup.find(\"table\")` or on an element you found before `rows = a_table.find(\"tr\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e05760b",
   "metadata": {},
   "source": [
    "You can seek for types of tags, classes or ids\n",
    "* `soup.find(\"h1\")`, \n",
    "* `soup.find(id=\"main_navigation\")`,\n",
    "* `soup.find(class=\"warning_message\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51351d45",
   "metadata": {},
   "source": [
    "But it is very frequent to fetch an element by its unique id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91709bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_row = soup.find(id='middle_row')\n",
    "\n",
    "print('Complete tag code: ', middle_row)\n",
    "print(\"Just the text in the tag: \", middle_row.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf9b0b0",
   "metadata": {},
   "source": [
    "## Find children:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca63b3",
   "metadata": {},
   "source": [
    "When, like above, a tag contains some children (tags inside it) you can extract them into a list. The example would be above table row `<tr></tr>` includes three table data `<td></td>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1bb1c",
   "metadata": {},
   "source": [
    "`.findChildren()` will give you alist with all tags inside of a given tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae897d9",
   "metadata": {},
   "source": [
    "You can specify exactly which chhildre, if you want, like with the `.find()`. So you could use \n",
    "* `.findChildren(\"tr\")` or\n",
    "* `.findChildren(class=\"warning_message\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334efab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_row = soup.find(id='middle_row')\n",
    "cells_in_the_row = middle_row.findChildren()\n",
    "for cell in cells_in_the_row:\n",
    "    print('Complete tag code: ', cell, \"Just the text in the tag: \", cell.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05356a0",
   "metadata": {},
   "source": [
    "You can dive deeper into certain tags, for example here you look for all divs from the (CSS) class called hipster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3834cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_elements = soup.find_all(\"div\", {\"class\" : \"hipster\" })\n",
    "for element in class_elements:\n",
    "    print('whole tag:\\n', str(element), '\\n')\n",
    "    print('Just the text: ', element.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98c357",
   "metadata": {},
   "source": [
    "Getting all the elements out of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a4504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all tables, since we only have 1, use the first in the list at index 0\n",
    "my_table = soup.find_all('table')[0]\n",
    "# or just use: my_table = soup.find('table')\n",
    "\n",
    "# loop the rows and keep the row number\n",
    "row_num = 0\n",
    "for row in my_table.find_all('tr'):\n",
    "    print(\"Row: \"+str(row_num))\n",
    "    row_num = row_num+1\n",
    "\n",
    "    #loop the cells in the row\n",
    "    for cell in row.find_all('td'):\n",
    "        print(\"whole html:\", str(cell)+\" \\tJust content: \"+cell.text)\n",
    "        \n",
    "# if you'd like, try to change this code to use .findChildren( ) rather t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8738651",
   "metadata": {},
   "source": [
    "## Minitask: Now attempt to scrape something from a real online website:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2bb3a",
   "metadata": {},
   "source": [
    "Use the above code to make a list of all the degrees available in business school of University of Edinburgh.\n",
    "* You will need to get the source of the page the list is on and feed it into the breautiful soup (see code above). (use this url instead of our demo website file://..... use this: https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12)\n",
    "* Get the html component that holds all the degrees. Use developer tools to identify what type of component it is (hint: ul stamds for \"unordered list\"). Does this component have a class or an id? How would you get a component when you know it's id? (hint: proxy_degreeList )\n",
    "* What type of a tag are the actual names of degrees in? (div, a, p, or something else) hint: what tag surround the name of the course?\n",
    "* Grab children of that type from the component with all names and in a loop, extract only the text of each of them. And print them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a8159",
   "metadata": {},
   "source": [
    "I am posting the solution lower down, but do try to solve it by yourself first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b56631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy-paste relevant parts of the code from above to start:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962b7c7",
   "metadata": {},
   "source": [
    "Only uncover the solutions once you tried to complete the task:\n",
    "\n",
    "CLICK HERE TO SEE THE THE HINT 1. \n",
    "1. You will need to get the source of the page the list is on and feed it into the breautiful soup (see code above). (use this url instead of our demo website file://..... use this: https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12)\n",
    "``` \n",
    "file_url = \"https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12\" \n",
    "website_source_code = urlopen(file_url) \n",
    "soup_degrees_website = BeautifulSoup(website_source_code, 'html.parser') \n",
    "``` \n",
    "\n",
    "CLICK HERE TO SEE THE THE HINT 2. \n",
    "\n",
    "2. get the html component that holds all the degrees. Use developer tools to identify what type of component it is (hint: ul stamds for \"unordered list\"). \n",
    "Does this component have a class or an id? How would you get a component when you know it's id? (hint: proxy_degreeList )\n",
    "``` \n",
    "degrees = soup_degrees_website.find(id='proxy_degreeList')\n",
    "``` \n",
    "\n",
    "CLICK HERE TO SEE THE THE HINT 3. \n",
    "\n",
    "3. What type of a tag are the actual names of degrees in? (div, a, p, or something else) hint: what tag surround the name of the course? \n",
    "``` \n",
    "for list_item in degrees.findChildren(\"a\"): \n",
    "``` \n",
    "\n",
    "CLICK HERE TO SEE THE THE HINT 4. \n",
    "\n",
    "4. Grab children of that type from the component with all names and in a loop, extract only the text of each of them. And print them. \n",
    "``` \n",
    "print(\"Degree Name:\", list_item.text) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"https://www.ed.ac.uk/studying/undergraduate/degrees/index.php?action=view&code=12\" \n",
    "website_source_code = urlopen(file_url) \n",
    "soup_degrees_website = BeautifulSoup(website_source_code, 'html.parser') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc87f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = soup_degrees_website.find(id='proxy_degreeList')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for list_item in degrees.findChildren(\"a\"):\n",
    "    print(\"Degree Name:\", list_item.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadcc965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
