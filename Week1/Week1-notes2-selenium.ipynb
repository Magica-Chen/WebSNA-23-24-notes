{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f06447",
   "metadata": {},
   "source": [
    "## Scraping reviews using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ef3a1",
   "metadata": {},
   "source": [
    "Here is another example of how Selenium can be used to interact with websites making use of Ajax (Asynchronous JavaScript):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9de56",
   "metadata": {},
   "source": [
    "### Selenium is a chrome automation framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871c737",
   "metadata": {},
   "source": [
    "It will enable us to tell chrome:\n",
    "* go to page bbc.co.uk/weather\n",
    "* \"click the work 'next'\"\n",
    "* scroll down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4444ce",
   "metadata": {},
   "source": [
    "Selenium will basically open a simplified version of Chrome, for a few seconds, use it and close it afterwards. You might even see it flash on your screen quickly. Then we will use beautiful soup to understand the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354eacfc",
   "metadata": {},
   "source": [
    "### BeautifulSoup is an HTML parsing framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c999f83e",
   "metadata": {},
   "source": [
    "It will enable us to:\n",
    "* copy the html of the tags eg. div, table\n",
    "* extract text from these tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f72416",
   "metadata": {},
   "source": [
    "## Getting selenium (don't skip this!)-- You need to download the chromedrive by yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab020b",
   "metadata": {},
   "source": [
    "1. find out which version of chrome you have, in chrome open page: chrome://settings/help\n",
    "2. Go to the list of selenium versions and find folder with yoru version (eg. 87.0.4280.88) https://chromedriver.storage.googleapis.com/index.html\n",
    "3. Go into the folder for your version and download the zip file with the version for your operating system (most likely `chromedriver_mac64.zip` or `chromedriver_win32.zip` ).\n",
    "4. unzip that file on yoru machine and put it in the folder where this notebook is. unzipped file will be called `chromedriver` or `chromedriver.exe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b3964",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2851b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method that will create a browser, suitable to your operating system\n",
    "import sys\n",
    "def get_a_browser():\n",
    "    if sys.platform.startswith('win32') or sys.platform.startswith('cygwin'):\n",
    "        return webdriver.Chrome() # windows\n",
    "    else:\n",
    "        return webdriver.Chrome('./chromedriver') # mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9069dcb",
   "metadata": {},
   "source": [
    "**Important Note**: allowing your system to run `chromedriver`. This needs to be done just once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863764a5",
   "metadata": {},
   "source": [
    "If you are on a mac, you will need to allow your system to use chromium. Run below cell, and you will likely see a warning the first time, click 'cancel' (don't click 'Delete')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0c6866",
   "metadata": {},
   "source": [
    "After you see the warning, go into `Settings > Security&Privacy > General` and `\"Allow Anyway\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea6539",
   "metadata": {},
   "source": [
    "On a pc the process will be simpler. When asked you'll need to allow computer to use the `chromedriver.exe` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c27429",
   "metadata": {},
   "source": [
    "## Task: let's try to scrape an interactive website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4613f1",
   "metadata": {},
   "source": [
    "What will be the weather in Edinburgh in 2 days?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ead1c7",
   "metadata": {},
   "source": [
    "You need a web browser, pen and paper!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a5724",
   "metadata": {},
   "source": [
    "In this task you will be asked to do something by yourself (using your web browser, mouse and keyboard), and then you will see how you cen program `Selenium` to do it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e75e3",
   "metadata": {},
   "source": [
    "**Use www.bbc.co.uk/weather to find out what time will be the sunrise in EDINBURGH next Sunday.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9589f2",
   "metadata": {},
   "source": [
    "Do it at least 3 times and observe all the steps you are taking. Make a very detailed list of all the steps, as if you had to describe them to someone over the phone without seeing their screen. See example below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3dbe8",
   "metadata": {},
   "source": [
    "it will look a bit like this:\n",
    "* ok, go to www.bbc.co.uk/weather and wait for it to load\n",
    "* scroll down, do you see a link with words 'Edinburgh' on it? Click it.\n",
    "* Wait a minute for it to load.\n",
    "* ok, now scroll down and ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c635dc0",
   "metadata": {},
   "source": [
    "When you are done with this exercise, we will try to instruct Selenium (Chrome automation tool) to do it for us. Do you think you can try to use Chrome Dev tools to make yoru steps more specific? eg. Instead of saying \"copy text in that bold link next to the word Sunrise\" try to say \"copy text from the html span item with a class `wr-c-astro-data__time`\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc3799f",
   "metadata": {},
   "source": [
    "**SERIOUSLY: Take a few minutes to do this. It will make you learn more from the below code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4de70",
   "metadata": {},
   "source": [
    "Ok. And now let's get the python to do it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = get_a_browser()\n",
    "\n",
    "# the url we want to open\n",
    "url = u'https://www.bbc.co.uk/weather'\n",
    "\n",
    "# the browser will start and load the webpage\n",
    "browser.get(url)\n",
    "\n",
    "# we wait 1 second to let the page load everything\n",
    "time.sleep(1)\n",
    "\n",
    "# we search for an element that is called 'Edinburgh', which is a button\n",
    "# the button can be clicked with the .click() function\n",
    "browser.find_element(By.LINK_TEXT,\"Edinburgh\").click();\n",
    "\n",
    "# sleep again, let everything load\n",
    "time.sleep(1)\n",
    "\n",
    "# we load the HTML body (the main page content without headers, footers, etc.)\n",
    "body = browser.find_element(By.TAG_NAME,'body')\n",
    "\n",
    "# we use seleniums' send_keys() function to physically scroll down where we want to click\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "# search for the next button to access the next day's weather\n",
    "try:\n",
    "    # link will look like \"Sun 12Dec\" so we use find_element_by_partial_link_text()\n",
    "    next_button = browser.find_element(By.PARTIAL_LINK_TEXT,'Sun ') \n",
    "    next_button.click()\n",
    "except NoSuchElementException:  #if such element does not exist, just stop looping\n",
    "    print(\"something went wrong. There was no Sunday link.\")\n",
    "    \n",
    "# load current view of the page into a soup\n",
    "soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "\"\"\"\n",
    "1. Find all the elements of class pros and print them \n",
    "2. These values include today's sunrise and sunset time, and the following 13 days.\n",
    "3. `browser.page_source` always get the whole page, so we can only find all\n",
    "4. A not smart, but workable solution is to count how many days between today and next sunday \n",
    "   and then choose the right element of all sunrise_tag list.\n",
    "\"\"\"\n",
    "# The whole list\n",
    "sunrise_tag = soup.find_all(\"span\", {\"class\" : 'wr-c-astro-data__time'})\n",
    "# How many days between today and the next sunday\n",
    "diff = int(next_button.get_attribute('id')[-1])\n",
    "\n",
    "print(\"Sunrise next Sunday: \", sunrise_tag[2*diff].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add33c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print(i, sunrise_tag[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb0b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecad658f",
   "metadata": {},
   "source": [
    "## Using API to access Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2606ce",
   "metadata": {},
   "source": [
    "Tweepy is a library that interfaces with the Twitter API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ab621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tweepy\n",
    "import tweepy\n",
    "# weeeply is a python library for accessing twitter data via twitter API. \n",
    "# # below I am sharing my demo credenmtials, they will work for testing it,\n",
    "# but for your project you'll need to create  your own credentials.\n",
    "# - create a twitter app with your twitter avound (one per group will do) https://developer.twitter.com/en/apps\n",
    "# - follow the tutorial on tweepy to set it up https://tweepy.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bearer_token = 'AAAAAAAAAAAAAAAAAAAAAMi%2BYAEAAAAA%2F2LLeju%2BgWlNK34g6PMT14scXzQ%3DHa0gE8PJoBnMVlnyoC3648USErcR6E86QadKgbKlBMIrKVNiYz'  # please generate it from twitter developer by yourself and put it here\n",
    "client = tweepy.Client(Bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Paginator(client.search_recent_tweets, \"University of Edinburgh\",\n",
    "                              max_results=100).flatten(limit=10):\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e297db8f",
   "metadata": {},
   "source": [
    "**More details, please refer to https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be557039",
   "metadata": {},
   "source": [
    "## Scraping tweets with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd428a",
   "metadata": {},
   "source": [
    "In this exercise we will use selenium to copy-paste some tweets straight from the twitter website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db35ce2",
   "metadata": {},
   "source": [
    "Be aware that there are terms and conditions about how you can use these coppied data. If you abuse or overuse scraping, twitter might block or throttle (slow down) your access to their site. (like, don't scrpate 1000s of tweets in 100 parrallel selenium windows)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f3e9a",
   "metadata": {},
   "source": [
    "This time, we import selenium first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method that will create a browser, suitable to your operating system\n",
    "import sys\n",
    "def get_a_browser():\n",
    "    if sys.platform.startswith('win32') or sys.platform.startswith('cygwin'):\n",
    "        return webdriver.Chrome() # windows\n",
    "    else:\n",
    "        return webdriver.Chrome('./chromedriver') # mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526cf5fb",
   "metadata": {},
   "source": [
    "The webdriver object can launch Internet Explorer, Firefox, and Chrome. Despite your preference, the ChromeDriver (which is a light version of Chrome) is the most widely used and complete one. You can use it to start a twitter page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5127c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch the browser\n",
    "browser = get_a_browser()\n",
    "\n",
    "# launch the Twitter search page\n",
    "twitter_url = u'https://twitter.com/search?q='\n",
    "\n",
    "# Add the search term\n",
    "query = u'%40edinburgh'\n",
    "# note: %40 is a code for @ symbol, so we're asking for the tweets with @edinburgh\n",
    "\n",
    "# Create the url\n",
    "url = twitter_url+query\n",
    "\n",
    "# Get the page\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40a064",
   "metadata": {},
   "source": [
    "Let's do this again and unleash the power of Selenium by using keyboard controls to manipulate a page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = get_a_browser()\n",
    "browser.get(url)\n",
    "\n",
    "# Let the Tweets load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find the body of the HTML page\n",
    "body = browser.find_element(By.TAG_NAME,'body')\n",
    "\n",
    "# Keep scrolling down using a simulation of the PAGE_DOWN button\n",
    "for _ in range(5):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "    \n",
    "# Get the tweets scores by their class (similar to Beautifulsoup's find())\n",
    "retweets = browser.find_elements(By.XPATH,\"//div[@data-testid='retweet']\");\n",
    "\n",
    "print(\"number of tweets scraped: \", len(retweets))\n",
    "\n",
    "# Print Tweets\n",
    "for retweet in retweets:\n",
    "    print(\"\\n--NEXT TWEET---\\n\", retweet.text, \"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b39e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
